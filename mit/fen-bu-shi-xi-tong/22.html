<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>22.Peer-to-peer: Trackerless Bittorrent and DHTs | CHKAOS</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/note/egg.png">
    <meta name="description" content="My Note Collection">
    
    <link rel="preload" href="/note/assets/css/0.styles.ba589cc9.css" as="style"><link rel="preload" href="/note/assets/js/app.d5006f3d.js" as="script"><link rel="preload" href="/note/assets/js/2.65e5b2f3.js" as="script"><link rel="preload" href="/note/assets/js/103.449bcd79.js" as="script"><link rel="prefetch" href="/note/assets/js/10.ae2f2d04.js"><link rel="prefetch" href="/note/assets/js/100.c68d38be.js"><link rel="prefetch" href="/note/assets/js/101.fd3e754f.js"><link rel="prefetch" href="/note/assets/js/102.5c217b08.js"><link rel="prefetch" href="/note/assets/js/104.1b5b375d.js"><link rel="prefetch" href="/note/assets/js/105.a61b2017.js"><link rel="prefetch" href="/note/assets/js/106.e81cfff0.js"><link rel="prefetch" href="/note/assets/js/107.a75923b3.js"><link rel="prefetch" href="/note/assets/js/108.891948b3.js"><link rel="prefetch" href="/note/assets/js/109.a2545875.js"><link rel="prefetch" href="/note/assets/js/11.4ab4a5a3.js"><link rel="prefetch" href="/note/assets/js/110.6d0886e8.js"><link rel="prefetch" href="/note/assets/js/12.255d9150.js"><link rel="prefetch" href="/note/assets/js/13.794e7ac8.js"><link rel="prefetch" href="/note/assets/js/14.d32c7fdd.js"><link rel="prefetch" href="/note/assets/js/15.67cfbf95.js"><link rel="prefetch" href="/note/assets/js/16.3c73a976.js"><link rel="prefetch" href="/note/assets/js/17.8806b699.js"><link rel="prefetch" href="/note/assets/js/18.378bd860.js"><link rel="prefetch" href="/note/assets/js/19.48c8434f.js"><link rel="prefetch" href="/note/assets/js/20.1fdb582e.js"><link rel="prefetch" href="/note/assets/js/21.3e08c9be.js"><link rel="prefetch" href="/note/assets/js/22.810fe1a0.js"><link rel="prefetch" href="/note/assets/js/23.5ba70e2d.js"><link rel="prefetch" href="/note/assets/js/24.9681b927.js"><link rel="prefetch" href="/note/assets/js/25.c0e5deaa.js"><link rel="prefetch" href="/note/assets/js/26.aae4bdc7.js"><link rel="prefetch" href="/note/assets/js/27.7f17e5f5.js"><link rel="prefetch" href="/note/assets/js/28.61ef96a0.js"><link rel="prefetch" href="/note/assets/js/29.f8d63307.js"><link rel="prefetch" href="/note/assets/js/3.031640f4.js"><link rel="prefetch" href="/note/assets/js/30.817d5cd9.js"><link rel="prefetch" href="/note/assets/js/31.e4ea696a.js"><link rel="prefetch" href="/note/assets/js/32.aba63c9c.js"><link rel="prefetch" href="/note/assets/js/33.1aa6facd.js"><link rel="prefetch" href="/note/assets/js/34.69d2bc3f.js"><link rel="prefetch" href="/note/assets/js/35.f82bd55f.js"><link rel="prefetch" href="/note/assets/js/36.20a42b33.js"><link rel="prefetch" href="/note/assets/js/37.7ab6c748.js"><link rel="prefetch" href="/note/assets/js/38.04cf7e1e.js"><link rel="prefetch" href="/note/assets/js/39.87ad9256.js"><link rel="prefetch" href="/note/assets/js/4.0876ef1d.js"><link rel="prefetch" href="/note/assets/js/40.fa12820d.js"><link rel="prefetch" href="/note/assets/js/41.22bd816e.js"><link rel="prefetch" href="/note/assets/js/42.c107915c.js"><link rel="prefetch" href="/note/assets/js/43.983b5fc5.js"><link rel="prefetch" href="/note/assets/js/44.75f6ceb2.js"><link rel="prefetch" href="/note/assets/js/45.98830da6.js"><link rel="prefetch" href="/note/assets/js/46.550f0b22.js"><link rel="prefetch" href="/note/assets/js/47.8fbd223c.js"><link rel="prefetch" href="/note/assets/js/48.edf4b3f9.js"><link rel="prefetch" href="/note/assets/js/49.7508a3de.js"><link rel="prefetch" href="/note/assets/js/5.369c3e08.js"><link rel="prefetch" href="/note/assets/js/50.04715961.js"><link rel="prefetch" href="/note/assets/js/51.277d9998.js"><link rel="prefetch" href="/note/assets/js/52.ebc26274.js"><link rel="prefetch" href="/note/assets/js/53.471c676f.js"><link rel="prefetch" href="/note/assets/js/54.9e46fdf4.js"><link rel="prefetch" href="/note/assets/js/55.8a98c441.js"><link rel="prefetch" href="/note/assets/js/56.b5f6e00a.js"><link rel="prefetch" href="/note/assets/js/57.f6fb0c39.js"><link rel="prefetch" href="/note/assets/js/58.d92a7b7d.js"><link rel="prefetch" href="/note/assets/js/59.33c88c84.js"><link rel="prefetch" href="/note/assets/js/6.34251819.js"><link rel="prefetch" href="/note/assets/js/60.68db27af.js"><link rel="prefetch" href="/note/assets/js/61.ce3eefe1.js"><link rel="prefetch" href="/note/assets/js/62.a3e76ed5.js"><link rel="prefetch" href="/note/assets/js/63.b9084887.js"><link rel="prefetch" href="/note/assets/js/64.e1d868ed.js"><link rel="prefetch" href="/note/assets/js/65.0d77e0a0.js"><link rel="prefetch" href="/note/assets/js/66.fe465e07.js"><link rel="prefetch" href="/note/assets/js/67.76ca73a0.js"><link rel="prefetch" href="/note/assets/js/68.2498dd7c.js"><link rel="prefetch" href="/note/assets/js/69.f03ab615.js"><link rel="prefetch" href="/note/assets/js/7.273a5831.js"><link rel="prefetch" href="/note/assets/js/70.cad85a7e.js"><link rel="prefetch" href="/note/assets/js/71.5dcb8b9a.js"><link rel="prefetch" href="/note/assets/js/72.827102a3.js"><link rel="prefetch" href="/note/assets/js/73.315b5fe4.js"><link rel="prefetch" href="/note/assets/js/74.def8de65.js"><link rel="prefetch" href="/note/assets/js/75.a54fced2.js"><link rel="prefetch" href="/note/assets/js/76.6cae1891.js"><link rel="prefetch" href="/note/assets/js/77.12cb32b9.js"><link rel="prefetch" href="/note/assets/js/78.5994be50.js"><link rel="prefetch" href="/note/assets/js/79.bbc37f01.js"><link rel="prefetch" href="/note/assets/js/8.ba3fa28e.js"><link rel="prefetch" href="/note/assets/js/80.eeb65418.js"><link rel="prefetch" href="/note/assets/js/81.f876286e.js"><link rel="prefetch" href="/note/assets/js/82.a58003e1.js"><link rel="prefetch" href="/note/assets/js/83.13c9c65b.js"><link rel="prefetch" href="/note/assets/js/84.dca226ee.js"><link rel="prefetch" href="/note/assets/js/85.38911042.js"><link rel="prefetch" href="/note/assets/js/86.4f2e3cde.js"><link rel="prefetch" href="/note/assets/js/87.bb576b86.js"><link rel="prefetch" href="/note/assets/js/88.ba3e1a83.js"><link rel="prefetch" href="/note/assets/js/89.cc281bcf.js"><link rel="prefetch" href="/note/assets/js/9.557b7160.js"><link rel="prefetch" href="/note/assets/js/90.b68af197.js"><link rel="prefetch" href="/note/assets/js/91.a0945e77.js"><link rel="prefetch" href="/note/assets/js/92.accc5e5d.js"><link rel="prefetch" href="/note/assets/js/93.682fd046.js"><link rel="prefetch" href="/note/assets/js/94.c47d39d0.js"><link rel="prefetch" href="/note/assets/js/95.6363826c.js"><link rel="prefetch" href="/note/assets/js/96.36edf40e.js"><link rel="prefetch" href="/note/assets/js/97.75b6c735.js"><link rel="prefetch" href="/note/assets/js/98.8b5d3421.js"><link rel="prefetch" href="/note/assets/js/99.e03485fe.js">
    <link rel="stylesheet" href="/note/assets/css/0.styles.ba589cc9.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/note/" class="home-link router-link-active"><img src="/note/favicon.png" alt="CHKAOS" class="logo"> <span class="site-name can-hide">CHKAOS</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/note/MIT/" class="nav-link">
  Mit
</a></div><div class="nav-item"><a href="/note/Leetcode/" class="nav-link">
  Leetcode
</a></div><div class="nav-item"><a href="/note/Interview/" class="nav-link">
  Interview
</a></div><div class="nav-item"><a href="http://chkaos.top" target="_blank" rel="noopener noreferrer" class="nav-link external">
  博客
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://github.com/chkaos/note" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/note/MIT/" class="nav-link">
  Mit
</a></div><div class="nav-item"><a href="/note/Leetcode/" class="nav-link">
  Leetcode
</a></div><div class="nav-item"><a href="/note/Interview/" class="nav-link">
  Interview
</a></div><div class="nav-item"><a href="http://chkaos.top" target="_blank" rel="noopener noreferrer" class="nav-link external">
  博客
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://github.com/chkaos/note" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><a href="/note/mit/" aria-current="page" class="sidebar-link">前言</a></li><li><a href="/note/mit/schedule.html" class="sidebar-link">计划</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>计算机科学与编程导论(python)</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>计算机科学数学</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>电子工程与计算机科学导论1</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>电子工程与计算机科学导论2(交流网络)</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>算法导论</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>软件构造</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>网络</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>计算机网络导论</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>操作系统</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>分布式系统</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/note/mit/fen-bu-shi-xi-tong/" aria-current="page" class="sidebar-link">6.824 分布式系统</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/01.html" class="sidebar-link">Introduction</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/02.html" class="sidebar-link">2: Infrastructure: RPC and threads</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/03.html" class="sidebar-link">3.Fault Tolerance: primary/backup replication</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/04.html" class="sidebar-link">4.Fault Tolerance: FDS Case Study</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/05.html" class="sidebar-link">5: Fault Tolerance:Paxos</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/06.html" class="sidebar-link">6: Fault Tolerance:Raft</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/07.html" class="sidebar-link">7.Guest lecturer: Russ Cox (Google/Go)</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/08.html" class="sidebar-link">8.Case Studies: Replicated File System -- Harp</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/09.html" class="sidebar-link">9. Distributed Computing: Sequential consistency</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/10.html" class="sidebar-link">10.Distributed Computing: Relaxed consistency</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/11.html" class="sidebar-link">11.Disconnected Operation: Version Vectors and File Synchronization</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/12.html" class="sidebar-link">13.Disconnected Operation: Eventual Consistency</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/13.html" class="sidebar-link">13.MapReduce revisited</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/14.html" class="sidebar-link">14.Spark Case Study</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/15.html" class="sidebar-link">15.Guest lecturer: Wilson Hsieh (Google)</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/16.html" class="sidebar-link">16.Scaling Memcache at Facebook</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/17.html" class="sidebar-link">17.Case Studies: Relaxed Consistency-PNUTS</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/18.html" class="sidebar-link">18. Case Studies:Dynamo</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/19.html" class="sidebar-link">19.Distributed systems in the real world (Guest lecturer: Emil Sit)</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/20.html" class="sidebar-link">20.Atomicity: Two-Phase Commit</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/21.html" class="sidebar-link">21.Atomicity: Optimistic Concurrency Control</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/22.html" aria-current="page" class="active sidebar-link">22.Peer-to-peer: Trackerless Bittorrent and DHTs</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/23.html" class="sidebar-link">23.Peer-to-peer: Bitcoin</a></li><li><a href="/note/mit/fen-bu-shi-xi-tong/24.html" class="sidebar-link">24.Project demos</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="_22-peer-to-peer-trackerless-bittorrent-and-dhts"><a href="#_22-peer-to-peer-trackerless-bittorrent-and-dhts" class="header-anchor">#</a> 22.Peer-to-peer: Trackerless Bittorrent and DHTs</h1> <p>Lecture outline:
peer-to-peer (P2P)
BitTorrent
DHTs
Chord</p> <p>Peer-to-peer
[user computers, files, direct xfers]
users computers talk directly to each other to implement service
in contrast to user computers talking to central servers
could be closed or open
examples:
skype, video and music players, file sharing</p> <p>Why might P2P be a win?
spreads network/caching costs over users
absence of server may mean:
easier to deploy
less chance of overload
single failure won't wreck the whole system
harder to attack</p> <p>Why don't all Internet services use P2P?
can be hard to find data items over millions of users
user computers not as reliable than managed servers
if open, can be attacked via evil participants</p> <p>The result is that P2P has some successful niches:
Client-client video/music, where serving costs are high
Chat (user to user anyway; privacy and control)
Popular data but owning organization has no money
No natural single owner or controller (Bitcoin)
Illegal file sharing</p> <p>Example: classic BitTorrent
a cooperative download system, very popular!
user clicks on download link for e.g. latest Linux kernel distribution
gets torrent file w/ content hash and IP address of tracker
user's BT client talks to tracker
tracker tells it list of other user clients w/ downloaded file
user't BT client talks to one or more client's w/ the file
user's BT client tells tracker it has a copy now too
user's BT client serves the file to others for a while
the point:
provides huge download b/w w/o expensive server/link</p> <p>BitTorrent can also use a DHT instead of / as well as a tracker
this is the topic of today's readings
BT clients cooperatively implement a giant key/value store
&quot;distributed hash table&quot;
the key is the file content hash (&quot;infohash&quot;)
the value is the IP address of a client willing to serve the file
Kademlia can store multiple values for a key
client does get(infohash) to find other clients willing to serve
and put(infohash, self) to register itself as willing to serve
client also joins the DHT to help implement it</p> <p>Why might the DHT be a win for BitTorrent?
single giant tracker, less fragmented than many trackers
so clients more likely to find each other
maybe a classic tracker too exposed to legal &amp;c attacks
it's not clear that BitTorrent depends heavily on the DHT
mostly a backup for classic trackers?</p> <p>How do DHTs work?</p> <p>Scalable DHT lookup:
Key/value store spread over millions of nodes
Typical DHT interface:
put(key, value)
get(key) -&gt; value
loose consistency; likely that get(k) sees put(k), but no guarantee
loose guarantees about keeping data alive</p> <p>Why is it hard?
Millions of participating nodes
Could broadcast/flood request -- but too many messages
Every node could know about every other node
Then hashing is easy
But keeping a million-node table up to date is hard
We want modest state, and modest number of messages/lookup</p> <p>Basic idea
Impose a data structure (e.g. tree) over the nodes
Each node has references to only a few other nodes
Lookups traverse the data structure -- &quot;routing&quot;
I.e. hop from node to node
DHT should route get() to same node as previous put()</p> <p>Example: The &quot;Chord&quot; peer-to-peer lookup system
By Stoica, Morris, Karger, Kaashoek and Balakrishnan; 2001</p> <p>Chord's ID-space topology
Ring: All IDs are 160-bit numbers, viewed in a ring.
Each node has an ID, randomly chosen</p> <p>Assignment of key IDs to node IDs?
Key stored on first node whose ID is equal to or greater than key ID.
Closeness is defined as the &quot;clockwise distance&quot;
If node and key IDs are uniform, we get reasonable load balance.
So keys IDs should be hashes (e.g. bittorrent infohash)</p> <p>Basic routing -- correct but slow
Query is at some node.
Node needs to forward the query to a node &quot;closer&quot; to key.
If we keep moving query closer, eventually we'll win.
Each node knows its &quot;successor&quot; on the ring.
n.lookup(k):
if n &lt; k &lt;= n.successor
return n.successor
else
forward to n.successor
I.e. forward query in a clockwise direction until done
n.successor must be correct!
otherwise we may skip over the responsible node
and get(k) won't see data inserted by put(k)</p> <p>Forwarding through successor is slow
Data structure is a linked list: O(n)
Can we make it more like a binary search?
Need to be able to halve the distance at each step.</p> <p>log(n) &quot;finger table&quot; routing:
Keep track of nodes exponentially further away:
New state: f[i] contains successor of n + 2^i
n.lookup(k):
if n &lt; k &lt;= n.successor:
return successor
else:
n' = closest_preceding_node(k) -- in f[]
forward to n'</p> <p>for a six-bit system, maybe node 8's looks like this:
0: 14
1: 14
2: 14
3: 21
4: 32
5: 42</p> <p>Why do lookups now take log(n) hops?
One of the fingers must take you roughly half-way to target</p> <p>There's a binary lookup tree rooted at every node
Threaded through other nodes' finger tables
This is <em>better</em> than simply arranging the nodes in a single tree
Every node acts as a root, so there's no root hotspot
But a lot more state in total</p> <p>Is log(n) fast or slow?
For a million nodes it's 20 hops.
If each hop takes 50 ms, lookups take a second.
If each hop has 10% chance of failure, it's a couple of timeouts.
So in practice log(n) is better than O(n) but not great.</p> <p>How does a new node acquire correct tables?
General approach:
Assume system starts out w/ correct routing tables.
Use routing tables to help the new node find information.
Add new node in a way that maintains correctness.
New node m:
Sends a lookup for its own key, to any existing node.
This yields m.successor
m asks its successor for its entire finger table.
At this point the new node can forward queries correctly
Tweaks its own finger table in background
By looking up each m + 2^i</p> <p>Does routing <em>to</em> new node m now work?
If m doesn't do anything,
lookup will go to where it would have gone before m joined.
I.e. to m's predecessor.
Which will return its n.successor -- which is not m.
So, for correctness, m's predecessor needs to set successor to m.
Each node keeps track of its current predecessor.
When m joins, tells its successor that its predecessor has changed.
Periodically ask your successor who its predecessor is:
If that node is closer to you, switch to that guy.
So if we have x m y
x.successor will be y (now incorrect)
y.predecessor will be m
x will ask its x.successor for predecessor
x learns about m
sets x.successor to m
tells m &quot;x is your predecessor&quot;
called &quot;stabilization&quot;
Correct successors are sufficient for correct lookups!</p> <p>What about concurrent joins?
Two new nodes with very close ids, might have same successor.
Example:
Initially 40 then 70
50 and 60 join concurrently
at first 40, 50, and 60 think their successor is 70!
which means lookups for e.g. 45 will yield 70, not 50
after one stabilization, 40 and 50 will learn about 60
then 40 will learn about 50</p> <p>To maintain log(n) lookups as nodes join,
Every one periodically looks up each finger (each n + 2^i)</p> <p>Chord's routing is conceptually similar to Kademlia's
Finger table similar to bucket levels
Both halve the metric distance for each step
Both are about speed and can be imprecise
n.successor similar to Kademlia's requirement that
each node know of all the nodes that are very close in xor-space
in both cases care is needed to ensure that different lookups
for same key converge on exactly the same node</p> <p>What about node failures?
Assume nodes fail w/o warning. Strictly harder than graceful departure.
Two issues:
Other nodes' routing tables refer to dead node.
Dead node's predecessor has no successor.
If you try to route via dead node, detect timeout, treat as empty table entry.
I.e. route to numerically closer entry instead.
For dead successor
Failed node might have been just before key ID!
So we need to know what its n.successor was
Maintain a <em>list</em> of successors: r successors.
Lookup answer is first live successor &gt;= key
or forward to <em>any</em> successor &lt; key</p> <p>Kademlia has a faster plan for this
send alpha (or k) lookup RPCs in parallel, to different nodes
send more lookups as previous ones return info about nodes closer to key
single non-responsive node won't cause lookup to suffer a timeout</p> <p>Dealing with unreachable nodes during routing is extremely important
&quot;Churn&quot; is very high in open p2p networks
People close their laptops, move WiFi APs, &amp;c pretty often
Measurement of Bittorrent/Kademlia suggest lookups are not very fast</p> <p>Geographical/network locality -- reducing lookup time
Lookup takes log(n) messages.
But they are to random nodes on the Internet!
Will often be very far away.
Can we route through nodes close to us on underlying network?
This boils down to whether we have choices:
If multiple correct next hops, we can try to choose closest.</p> <p>Idea:
to fill a finger table entry, collect multiple nodes near n+2^i on ring
perhaps by asking successor to n+2^i for its r successors
use lowest-ping one as i'th finger table entry</p> <p>What's the effect?
Individual hops are lower latency.
But less and less choice (lower node density) as you get close in ID space.
So last few hops likely to be very long.
Though if you are reading, and any replica will do,
you still have choice even at the end.</p> <p>What about security?
Self-authenticating data, e.g. key = SHA1(value)
So DHT node can't forge data
Of course it's annoying to have immutable data...
Can someone cause millions of made-up hosts to join?
They don't exist, so routing will break?
Don't believe new node unless it responds to ping, w/ random token.
Can a DHT node claim that data doesn't exist?
Yes, though perhaps you can check other replicas
Can a host join w/ IDs chosen to sit under every replica?
Or &quot;join&quot; many times, so it is most of the DHT nodes?
Maybe you can require (and check) that node ID = SHA1(IP address)</p> <p>Why not just keep complete routing tables?
So you can always route in one hop?
Danger in large systems: timeouts or cost of keeping tables up to date.</p> <p>How to manage data?
Here is the most popular plan.
DHT doesn't guarantee durable storage
So whoever inserted must re-insert periodically if they care
May want to automatically expire if data goes stale (bittorrent)
DHT does replicate each key/value item
On the nodes with IDs closest to the key, where looks will find them
Replication can help spread lookup load as well as tolerate faults
When a node joins:
successor moves some keys to it
When a node fails:
successor probably already has a replica
but r'th successor now needs a copy</p> <p>Retrospective
DHTs seem very promising for finding data in large p2p systems
Decentralization seems good for load, fault tolerance
But: the security problems are difficult
But: churn is a serious problem, particularly if log(n) is big
So DHTs have not had the impact that many hoped for</p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">lastUpdate:</span> <span class="time">4/6/2021, 2:11:34 PM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/note/mit/fen-bu-shi-xi-tong/21.html" class="prev">
        21.Atomicity: Optimistic Concurrency Control
      </a></span> <span class="next"><a href="/note/mit/fen-bu-shi-xi-tong/23.html">
        23.Peer-to-peer: Bitcoin
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/note/assets/js/app.d5006f3d.js" defer></script><script src="/note/assets/js/2.65e5b2f3.js" defer></script><script src="/note/assets/js/103.449bcd79.js" defer></script>
  </body>
</html>
