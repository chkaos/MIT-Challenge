(window.webpackJsonp=window.webpackJsonp||[]).push([[91],{468:function(e,a,o){"use strict";o.r(a);var n=o(45),t=Object(n.a)({},(function(){var e=this,a=e.$createElement,o=e._self._c||a;return o("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[o("h1",{attrs:{id:"_10-distributed-computing-relaxed-consistency"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_10-distributed-computing-relaxed-consistency"}},[e._v("#")]),e._v(" 10.Distributed Computing: Relaxed consistency")]),e._v(" "),o("p",[e._v("Topic: consistency models\n= Interaction of reads/writes on different processors\nMany choices of models!\nLax model => greater freedom to optimize\nStrict model => matches programmer intuition (e.g. read sees latest write)\nThis tradeoff is a huge factor in many designs\nTreadmarks is a case study of relaxing to improve performance")]),e._v(" "),o("p",[e._v("Treadmarks high level goals?\nBetter DSM performance\nRun existing parallel code")]),e._v(" "),o("p",[e._v("What specific problems with previous DSM are they trying to fix?\nfalse sharing: two machines r/w different vars on same page\nM1 writes x, M2 writes y\nM1 writes x, M2 just reads y\nQ: what does IVY do in this situation?\nwrite amplification: a one byte write turns into a whole-page transfer")]),e._v(" "),o("p",[e._v("First Goal: eliminate write amplification\ndon't send whole page, just written bytes")]),e._v(" "),o("p",[e._v('Big idea: write diffs\non M1 write fault:\ntell other hosts to invalidate but keep hidden copy\nM1 makes hidden copy as well\non M2 fault:\nM2 asks M1 for recent modifications\nM1 "diffs" current page against hidden copy\nM1 send diffs to M2 (and all machines w/ copy of this page)\nM2 applies diffs to its hidden copy\nM1 marks page r/o')]),e._v(" "),o("p",[e._v("Q: do write diffs change the consistency model?\nAt most one writeable copy, so writes are ordered\nNo writing while any copy is readable, so no stale reads\nReadable copies are up to date, so no stale reads\nStill sequentially consistent")]),e._v(" "),o("p",[e._v("Q: do write diffs fix false sharing?")]),e._v(" "),o("p",[e._v("Next goal: allow multiple readers+writers\nto cope with false sharing\n=> don't invalidate others when a machine writes\n=> don't demote writers to r/o when another machine reads\n=> multiple "),o("em",[e._v("different")]),e._v(" copies of a page!\nwhich should a reader look at?\ndiffs help: can merge writes to same page\nbut when to send the diffs?\nno invalidations -> no page faults -> what triggers sending diffs?")]),e._v(" "),o("p",[e._v("Big idea: release consistency (RC)\nno-one should read data w/o holding a lock!\nso let's assume a lock server\nsend out write diffs on release\nto "),o("em",[e._v("all")]),e._v(" machines with a copy of the written page(s)")]),e._v(" "),o("p",[e._v("Example 1 (RC and false sharing)\nx and y are on the same page\nM0: a1 for(...) x++ r1\nM1: a2 for(...) y++ r2  a1 print x, y r1\nWhat does RC do?\nM0 and M1 both get cached writeable copy of the page\nduring release, each computes diffs against original page,\nand sends them to all copies\nM1's a1 causes it to wait until M0's release\nso M1 will see M0's writes")]),e._v(" "),o("p",[e._v("Q: what is the performance benefit of RC?\nWhat does IVY do with Example 1?\nmultiple machines can have copies of a page, even when 1 or more writes\n=> no bouncing of pages due to false sharing\n=> read copies can co-exist with writers")]),e._v(" "),o("p",[e._v("Q: does RC change the consistency model? yes!\nM1 won't see M0's writes until M0 releases a lock\nI.e. M1 can see a stale copy of x; not possible w/ IVY\nif you always lock:\nlocks force order -> no stale reads")]),e._v(" "),o("p",[e._v("Q: what if you don't lock?\nreads can return stale data\nconcurrent writes to same var -> trouble")]),e._v(" "),o("p",[e._v("Q: does RC make sense without write diffs?\nprobably not: diffs needed to reconcile concurrent writes to same page")]),e._v(" "),o("p",[e._v("Big idea: lazy release consistency (LRC)\nonly send write diffs to next acquirer of released lock,\nnot to everyone")]),e._v(" "),o("p",[e._v("Example 2 (lazyness)\nx and y on same page (otherwise IVY avoids copy too)\neveryone starts with a copy of that page\nM0: a1 x=1 r1\nM1:           a2 y=1 r2\nM2:                     a1 print x r1\nWhat does LRC do?\nM2 only asks previous holder of lock 1 for write diffs\nM2 does not see M1's y=1, even tho on same page (so print y would be stale)\nWhat does RC do?\nWhat does IVY do?")]),e._v(" "),o("p",[e._v("Q: what's the performance win from LRC?\nif you don't acquire lock on object, you don't see updates to it\n=> if you use just some vars on a page, you don't see writes to others\n=> less network traffic")]),e._v(" "),o("p",[e._v('Q: does LRC provide the same consistency model as RC?\nno: LRC hides some writes that RC reveals\nin above example, RC reveals y=1 to M2, LRC does not reveal\nso "M2: print x, y" might print fresh data for RC, stale for LRC\ndepends on whether print is before/after M1\'s release')]),e._v(" "),o("p",[e._v("Q: is LRC a win over IVY if each variable on a separate page?\nor a win over IVY plus write diffs?\nnote IVY's fault-driven page reads are lazy at page granularity")]),e._v(" "),o("p",[e._v("Do we think all threaded/locking code will work with LRC?\nStale reads unless every shared memory location is locked!\nDo programs lock every shared memory location they read?\nNo: people lock to make updates atomic.\nif no concurrent update possible, people don't lock.")]),e._v(" "),o("p",[e._v("Example 3 (programs don't lock all shared data)\nx, y, and z on the same page\nM0: x := 7 a1 y = &x r1\nM1:                    a1 a2 z = y r2 r1\nM2:                                       a2 print *z r2\nwill M2 print 7?\nLRC as described so far in this lecture would "),o("em",[e._v("not")]),e._v(" print 7!\nM2 will see the pointer in z, but will have stale content in x's memory.")]),e._v(" "),o("p",[e._v('For real programs to work, Treadmarks must provide "causal consistency":\nwhen you see a value,\nyou also see other values which might have influenced its computation.\n"influenced" means "processor might have read".')]),e._v(" "),o("p",[e._v('How to track which writes influenced a value?\nNumber each machine\'s releases -- "interval" numbers\nEach machine tracks highest write it has seen from each other machine\na "Vector Timestamp"\nTag each release with current VT\nOn acquire, tell previous holder your VT\ndifference indicates which writes need to be sent\n(annotate previous example)')]),e._v(" "),o("p",[e._v('VTs order writes to same variable by different machines:\nM0: a1 x=1 r1  a2 y=9 r2\nM1:              a1 x=2 r1\nM2:                           a1 a2 z = x + y r2 r1\nM2 is going to hear "x=1" from M0, and "x=2" from M1.\nHow does M2 know what to do?')]),e._v(" "),o("p",[e._v("Could the VTs for two values of the same variable not be ordered?\nM0: a1 x=1 r1\nM1:              a2 x=2 r2\nM2:                           a1 a2 print x r2 r1")]),e._v(" "),o("p",[e._v("Summary of programmer rules / system guarantees")]),e._v(" "),o("ol",[o("li",[e._v("each shared variable protected by some lock")]),e._v(" "),o("li",[e._v('lock before writing a shared variable\nto order writes to same var\notherwise "latest value" not well defined')]),e._v(" "),o("li",[e._v("lock before reading a shared variable\nto get the latest version")]),e._v(" "),o("li",[e._v("if no lock for read, guaranteed to see values that\ncontributed to the variables you did lock")])]),e._v(" "),o("p",[e._v("Example of when LRC might work too hard.\nM0: a2 z=99 r2  a1 x=1 r1\nM1:                            a1 y=x r1\nTreadMarks will send z to M1, because it comes before x=1 in VT order.\nAssuming x and z are on the same page.\nEven if on different pages, M1 must invalidate z's page.\nBut M1 doesn't use z.\nHow could a system understand that z isn't needed?\nRequire locking of all data you read\n=> Relax the causal part of the LRC model")]),e._v(" "),o("p",[e._v("Q: could TreadMarks work without using VM page protection?\nit uses VM to\ndetect writes to avoid making hidden copies (for diffs) if not needed\ndetect reads to pages => know whether to fetch a diff\nneither is really crucial\nso TM doesn't depend on VM as much as IVY does\nIVY used VM faults to decide what data has to be moved, and when\nTM uses acquire()/release() and diffs for that purpose")]),e._v(" "),o("p",[e._v("Performance?")]),e._v(" "),o("p",[e._v('Figure 3 shows mostly good scaling\nis that the same as "good"?\nthough apparently Water does lots of locking / sharing')]),e._v(" "),o("p",[e._v("How close are they to best possible performance?\nmaybe Figure 5 implies there is only about 20% fat to be cut")]),e._v(" "),o("p",[e._v("Does LRC beat previous DSM schemes?\nthey only compare against their own straw-man ERC\nnot against best known prior work\nFigure 9 suggests lazyness only a win for Water\nmost pages used by most processors, so eager moves a lot of data")]),e._v(" "),o("p",[e._v("What happened to DSM?\nThe cluster approach was a great idea\nTargeting "),o("em",[e._v("existing")]),e._v(" threaded code was not a long-term win\nOvertaken by MapReduce and successors\nMR tolerates faults\nMR guides programmer to good split of data and computation\nBUT people have found MR too rigid for many parallel tasks\nThe last word has not been spoken here\nMuch recent work on flexible memory-like cluster programming models\nRDDs/Spark, FaRM, Piccolo")])])}),[],!1,null,null,null);a.default=t.exports}}]);