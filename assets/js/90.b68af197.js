(window.webpackJsonp=window.webpackJsonp||[]).push([[90],{467:function(e,a,n){"use strict";n.r(a);var t=n(45),o=Object(t.a)({},(function(){var e=this,a=e.$createElement,n=e._self._c||a;return n("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[n("h1",{attrs:{id:"_9-distributed-computing-sequential-consistency"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_9-distributed-computing-sequential-consistency"}},[e._v("#")]),e._v(" 9. Distributed Computing: Sequential consistency")]),e._v(" "),n("p",[e._v("New Topic: Distributed computing\nThe Big Idea: your huge computation on a room full of cheap computers!\nAn old and difficult goal; many approaches; much progress; still hot.\nOther cluster computing papers: TreadMarks, MapReduce, Spark\nSub-topic: sharing framework (RPC? memory? storage? MapReduce?)\nSub-topic: detailed semantics")]),e._v(" "),n("p",[e._v("Today's approach: distributed shared memory (DSM)\nYou all know how to write parallel (threaded) Go programs\nLet's farm the threads out to a big cluster of machines!\nWhat's missing? shared memory!")]),e._v(" "),n("p",[e._v("DSM plan:\nProgrammer writes parallel program: threads, shared variables, locks, &c\nDSM system farms out threads to a cluster of machines\nDSM system creates illusion of single shared memory\n[diagram: LAN, machines w/ RAM, MGR]")]),e._v(" "),n("p",[e._v("DSM advantages\nfamiliar model -- shared variables, locks, &c\ngeneral purpose (compared to e.g. MapReduce)\ncan use existing apps and libraries written for multiprocessors\nlots of machines on a LAN much cheaper than huge multiprocessor")]),e._v(" "),n("p",[e._v("But:\nmachines on a LAN don't actually share memory")]),e._v(" "),n("p",[e._v("Approach:\nUse hardware's virtual memory protection (r/w vs r/o vs invalid)\nGeneral idea illustrated with 2 machines:\nPart of the address space starts out on M0\nOn M1, marked invalid\nPart of the address space start out on M1\nOn M0, marked invalid\nA thread of the application on M1 may refer to an address that lives on M0\nIf thread LD/ST to that \"shared\" address, M1's hardware will take a page fault\nBecause page is marked invalid\nOS propagates page fault to DSM runtime\nDSM runtime can fetch page from M0\nDSM on M0, marks page invalid, and sends page to M1\nDSM on M1 receives it from M0, copies it to underlying physical memory\nDSM on M1 marks the page valid\nDSM returns from page fault handler\nHardware retries LD/ST\nRuns threaded code w/o modification\ne.g. matrix multiply, physical simulation, sort")]),e._v(" "),n("p",[e._v("Challenges:\nMemory model (does memory act like programmers expect it to act?)\nPerformance (is it fast?)")]),e._v(" "),n("p",[e._v("How could there be any doubt about how memory acts?")]),e._v(" "),n("p",[e._v("Example\nx and y start out = 0\nthread 0:\nx = 1\nif y == 0:\nprint yes\nthread 1:\ny = 1\nif x == 0:\nprint yes")]),e._v(" "),n("p",[e._v("Would it be OK if both threads printed yes?\nIs that even possible?")]),e._v(" "),n("p",[e._v('Could they both print "yes" if this were a Go program?\nHow could that happen?\nWhy is that allowed?')]),e._v(" "),n("p",[e._v("What is a memory model?\nIt explains how program reads/writes in different threads interact.\nA contract:\nIt gives the compiler/runtime/hardware some freedom to optimize.\nIt gives the programmer some guarantees to rely on.\nYou need one on a multiprocessor (e.g. for the labs).\nYou "),n("em",[e._v("really")]),e._v(" need one for a DSM system.\nThere are many memory models!\nWith different optimization/convenience trade-offs.\nOften called a consistency model.\nNeeded for any memory-like or storage system (e.g. the labs).")]),e._v(" "),n("p",[e._v("What does Go's memory model say?\nIt answers questions about whether, when and in what order reads and\nwrites by different threads interact.\nIt answers questions like:\nIf a thread says x=1;y=2, could other threads see y=2 but x=0?\nIf a thread says x=1;tmp=y, must other threads see x=1 after read completes?\nBy default: Go makes NO GUARANTEE about when/whether/order in which one thread's\nmemory references interact with other threads.\nA write only becomes visible if writer then interacts with reader\nvia a \"synchronization event\", and then the reader reads.\nE.g. write releases a lock, reader acquires the lock.")]),e._v(" "),n("p",[e._v("So this Go code (from Lab tests!) is not guaranteed to do what I might think:\ndone := false\ngo func() {\nwhile done == false {\n...\n}\n}\n...\ndone = true")]),e._v(" "),n("p",[e._v("The memory model says the thread may never see the change to done.\nThough in practice, with current compiler, this seems to work.\nSolutions: lock around ALL USES of done; or (better) a channel.")]),e._v(" "),n("p",[e._v("Why does Go break my perfectly intuitive and straightforward code?\nBecause an optimizing compiler could thereby generate better code.\nModel allows any optimization that keeps an individual thread's results the same:\nchange the order of statements, including variable reads and writes.\nperhaps start a slow read early.\nput a variable in a register, so changes aren't visible to other cores.\ntotally eliminate code or variables (done=true is useless!)\nevaluate at compile-time (done is always false!)\nAnd because some CPU hardware re-orders reads/writes.\nE.g. 2nd write may be visible before 1st if 1st must fetch line from RAM.\nE.g. example's load of y may happen before x=1.")]),e._v(" "),n("p",[e._v("Back to DSM.")]),e._v(" "),n("p",[e._v("Naive distributed shared memory\n[diagram]\nM0, M1, M2, LAN\neach machine has a local copy of all of memory\nread: from local memory\nwrite: send update msg to each other host (but don't wait)\nfast: never waits for communication")]),e._v(" "),n("p",[e._v("Does this naive DSM work well?\nWhat will it do with the example?\nThis naive DSM is fast but not programmer-friendly.")]),e._v(" "),n("p",[e._v('The paper\'s memory model: sequential consistency\nFormal version of "a read sees the most recent write".\nThis is a relatively strict and programmer-friendly memory model.\n"Most recent" is only meaningful if there\'s an overall order.')]),e._v(" "),n("p",[e._v("Sequential consistency's definition:\nThe result of any execution must be the same as if\n1. the operations of all the processors executed in some total order,\n2. each processor's operations appear in the total order in program order,\n3. all operations see results consistent with the total order\ni.e. read sees most recent write in the order")]),e._v(" "),n("p",[e._v("Would sequential consistency cause our example to get the intuitive result?\nM0: Wx1 Ry?\nM1: Wy1 Rx?\nThe system must get the same results as if it had merged these into one order,\nmaintaining the order of each machine's operations.\nA few possibilities:\nWx1 Ry0 Wy1 Rx1\nWx1 Wy1 Ry1 Rx1\nWx1 Wy1 Rx1 Ry1\nand some more symmetric ones (swap M0 and M1)\nthe second read (either x or y) is always 1, as you'd hope\nWhat is forbidden?\nWx1 Ry0 Wy1 Rx0 -- read didn't see preceding write (naive system did this)\nRy0 Wy1 Rx0 Wx1 -- M0's instructions out of order (some CPUs do this)")]),e._v(" "),n("p",[e._v("This example is a good diagnostic for sequential consistency.")]),e._v(" "),n("p",[e._v('Sequential consistency performance is ok but not great\nE.g. system must communicate M0\'s x=1 to M1 before M0 can proceed to read y\nTo ensure results consistent with a single total order\n(Second "forbidden" example)\nThis communication takes time!')]),e._v(" "),n("p",[e._v("A simple implementation of sequential consistency\n[diagram]\nsingle memory server\neach machine sends r/w ops to server, in order, waiting for reply\nserver picks order among waiting ops\nserver executes one by one, sending replies")]),e._v(" "),n("p",[e._v("This simple implementation will be slow\nsingle server will get overloaded\nno local cache, so all operations wait for server")]),e._v(" "),n("p",[e._v("Which brings us to IVY\nIVY = Integrated  shared  Virtual  memory  at Yale\nMemory Coherence in Shared Virtual Memory Systems, Li and Hudak, PODC 1986")]),e._v(" "),n("p",[e._v("IVY big picture\n[diagram: M0 w/ a few pages of mem, M1 w/ a few pages, LAN]\nOperates on pages of memory, stored in machine DRAM (no mem server)\nEach page present in each machine's virtual address space\nOn each a machine, a page might be invalid, read-only, or read-write\nUses VM hardware to intercept reads/writes")]),e._v(" "),n("p",[e._v("Invariant: a page is either:\nRead/write on one machine, invalid on all others; or\nRead/only on >= 1 machines, read/write on none")]),e._v(" "),n("p",[e._v("Basic machinery:\nRead fault on an invalid page:\nDemote R/W (if any) to R/O\nCopy page\nMark local copy R/O\nWrite fault on an R/O page:\nInvalidate all copies\nMark local copy R/W")]),e._v(" "),n("p",[e._v("IVY allows multiple reader copies between writes\nFor speed -- local reads are fast\nNo need to force an order for reads that occur between two writes\nLet them occur concurrently -- a copy of the page at each reader")]),e._v(" "),n("p",[e._v("Why crucial to invalidate all copies before write?\nOnce a write completes, all subsequent reads "),n("em",[e._v("must")]),e._v(" see new data\nOtherwise we break our example, and don't get sequential consistency")]),e._v(" "),n("p",[e._v("How does IVY do on the example?\nI.e. could both M0 and M1 print \"yes\"?\nIf M0 sees y == 0,\nM1 hasn't done it's write to y (no stale data == reads see prior writes),\nM1 hasn't read x (each machine in order),\nM1 must see x==1 (no stale data == reads see prior writes).")]),e._v(" "),n("p",[e._v("Message types:\n[don't list these on board, just for reference]\nRQ read query (reader to MGR)\nRF read forward (MGR to owner)\nRD read data (owner to reader)\nRC read confirm (reader to MGR)\n&c")]),e._v(" "),n("p",[e._v("(see ivy-code.txt on web site)")]),e._v(" "),n("p",[e._v("scenario 1: M0 has writeable copy (is owner), M1 wants to read\n[time diagram: MGR 0 1]\n0. page fault on M1, since page must have been marked invalid")]),e._v(" "),n("ol",[n("li",[e._v("M1 sends RQ to MGR")]),e._v(" "),n("li",[e._v("MGR sends RF to M0, MGR adds M1 to copy_set")]),e._v(" "),n("li",[e._v("M0 marks page as access=read, sends RD to M1")]),e._v(" "),n("li",[e._v("M1 marks access=read, sends RC to MGR")])]),e._v(" "),n("p",[e._v("scenario 2: now M2 wants to write\n[time diagram: MGR 0 1 2]\n0. page fault on M2")]),e._v(" "),n("ol",[n("li",[e._v("M2 sends WQ to MGR")]),e._v(" "),n("li",[e._v("MGR sends IV to copy_set (i.e. M1)")]),e._v(" "),n("li",[e._v("M1 sends IC msg to MGR")]),e._v(" "),n("li",[e._v("MGR sends WF to M0, sets owner=M2, copy_set={}")]),e._v(" "),n("li",[e._v("M0 sends WD to M2, access=none")]),e._v(" "),n("li",[e._v("M2 marks r/w, sends WC to MGR")])]),e._v(" "),n("p",[e._v("what if two machines want to write the same page at the same time?")]),e._v(" "),n("p",[e._v("what if one machine reads just as ownership is changing hands?")]),e._v(" "),n("p",[e._v("If M0 issues x=1 at time=10, and M1 issues x=2 at time=20,\nis the resulting x value always x?\nNo: messages can be slow, MGR processes them in arbitrary order.\nYou cannot use wall-clock time to reason about sequential consistency.")]),e._v(" "),n("p",[e._v("what if there were no IC message?\n(this is The Question)\ni.e. MGR didn't wait for holders of copies to ack?")]),e._v(" "),n("p",[e._v("what if there were no WC message?\ne.g. MGR unlocked after sending WF to M0?\nMGR would send subsequent RF, WF to M2 (new owner)\nWhat if such a WF/RF arrived at M2 before WD?\nNo problem! M2 has ptable[p].lock locked until it gets WD\nRC + info[p].lock prevents RF from being overtaken by a WF\nso it's not clear why WC is needed!\nbut I am not confident in this conclusion")]),e._v(" "),n("p",[e._v("In what situations will IVY perform well?")]),e._v(" "),n("ol",[n("li",[e._v("Page read by many machines, written by none")]),e._v(" "),n("li",[e._v("Page written by just one machine at a time, not used at all by others\nCool that IVY moves pages around in response to changing use patterns")])]),e._v(" "),n("p",[e._v("Will page size of e.g. 4096 bytes be good or bad?\ngood if spatial locality, i.e. program looks at large blocks of data\nbad if program writes just a few bytes in a page\nsubsequent readers copy whole page just to get a few new bytes\nbad if false sharing\ni.e. two unrelated variables on the same page\nand at least one is frequently written\npage will bounce between different machines\neven read-only users of a non-changing variable will get invalidations\neven though those computers never use the same location")]),e._v(" "),n("p",[e._v("What about IVY's performance?\nafter all, the point was speedup via parallelism")]),e._v(" "),n("p",[e._v("What's the best we could hope for in terms of performance?\nNx faster on N machines")]),e._v(" "),n("p",[e._v("What might prevent us from getting Nx speedup?\nApplication is inherently non-scalable\nCan't be split into parallel activities\nApplication communicates too many bytes\nSo network prevents more machines yielding more performance\nToo many small reads/writes to shared pages\nEven if # bytes is small, IVY makes this expensive")]),e._v(" "),n("p",[e._v("How well do they do?\nFigure 4: near-linear for PDE\nFigure 6: very sub-linear for sort\nFigure 7: near-linear for matrix multiply")]),e._v(" "),n("p",[e._v('Why did sort do poorly?\n"block odd-even merge-split"\nHere\'s my guess\nN machines, data in 2'),n("em",[e._v("N partitions\nPhase 1: Local sort of 2")]),e._v("N partitions for N machines\nPhase 2: 2N-1 merge-splits; each round sends all data over network\nPhase 1 probably gets linear speedup\nPhase 2 probably does not -- limited by LAN speed\nalso more machines may mean more rounds\nSo for small # machines, local sort dominates, more machines helps\nFor large # machines, communication dominates, more machines don't help\nAlso, more machines shifts from n*log(n) local sort to n^2 bubble-ish short")]),e._v(" "),n("p",[e._v("How could one speed up IVY?\nnext lecture: relax the consistency model\nallow multiple writers to same page!")]),e._v(" "),n("hr"),e._v(" "),n("p",[e._v("Paper intro says DSM subsumes RPC -- is that true?\nWhen would DSM be better than RPC?\nMore transparent. Easier to program.\nWhen would RPC be better?\nIsolation. Control over communication. Tolerate latency.\nPortability. Define your own semantics.\nMight you still want RPC in your DSM system? For efficient sleep/wakeup?")]),e._v(" "),n("p",[e._v("Known problems in Section 3.1 pseudo-code\nFault handlers must wait for owner to send p before confirming to manager\nDeadlock if owner has page r/o and takes write fault\nWorrisome that no clear order ptable[p].lock vs info[p].lock\nWrite server / manager must set owner=request_node\nManager parts of fault handlers don't ask owner for the page\nDoes processing of the invalidate request hold ptable[p].lock?\nprobably can't -- deadlock")]),e._v(" "),n("p",[e._v("Real-world uses of distributed shared memory?\n(these are from searching the web, not direct knowledge)\nhttps://numascale.com/numa_technology.html\nhttp://hazelcast.com/products/hazelcast/\nhttp://www.dell.com/downloads/global/power/ps1q08-50080247-Intel.pdf\nhttp://www.scalemp.com/solutions/shared-memory/")])])}),[],!1,null,null,null);a.default=o.exports}}]);