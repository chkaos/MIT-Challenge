(window.webpackJsonp=window.webpackJsonp||[]).push([[82],{459:function(e,t,a){"use strict";a.r(t);var n=a(45),o=Object(n.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"introduction"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#introduction"}},[e._v("#")]),e._v(" Introduction")]),e._v(" "),a("p",[e._v("6.824 2021 Lecture 1: Introduction")]),e._v(" "),a("p",[e._v("6.824: Distributed Systems Engineering")]),e._v(" "),a("p",[e._v("What is a distributed system?\nmultiple cooperating computers\nstorage for big web sites, MapReduce, peer-to-peer sharing, &c\nlots of critical infrastructure is distributed")]),e._v(" "),a("p",[e._v("Why do people build distributed systems?\nto increase capacity via parallelism\nto tolerate faults via replication\nto place computing physically close to external entities\nto achieve security via isolation")]),e._v(" "),a("p",[e._v("But:\nmany concurrent parts, complex interactions\nmust cope with partial failure\ntricky to realize performance potential")]),e._v(" "),a("p",[e._v("Why take this course?\ninteresting -- hard problems, powerful solutions\nused by real systems -- driven by the rise of big Web sites\nactive research area -- important unsolved problems\nhands-on -- you'll build real systems in the labs")]),e._v(" "),a("p",[e._v("COURSE STRUCTURE")]),e._v(" "),a("p",[e._v("http://pdos.csail.mit.edu/6.824")]),e._v(" "),a("p",[e._v("Course staff:\nFrans Kaashoek, lecturer\nLily Tsai, TA\nCel Skeggs, TA\nDavid Morejon, TA\nJose Javier Gonzalez, TA")]),e._v(" "),a("p",[e._v("Course components:\nlectures\npapers\ntwo exams\nlabs\nfinal project (optional)")]),e._v(" "),a("p",[e._v("Lectures:\nbig ideas, paper discussion, and labs\nwill be video-taped, available online")]),e._v(" "),a("p",[e._v("Papers:\nresearch papers, some classic, some new\nproblems, ideas, implementation details, evaluation\nmany lectures focus on papers\nplease read papers before class!\neach paper has a short question for you to answer\nand we ask you to send us a question you have about the paper\nsubmit question&answer before start of lecture")]),e._v(" "),a("p",[e._v("Exams:\nMid-term exam in class\nFinal exam during finals week\nMostly about papers and labs")]),e._v(" "),a("p",[e._v("Labs:\ngoal: deeper understanding of some important techniques\ngoal: experience with distributed programming\nfirst lab is due a week from Friday\none per week after that for a while")]),e._v(" "),a("p",[e._v("Lab 1: MapReduce\nLab 2: replication for fault-tolerance using Raft\nLab 3: fault-tolerant key/value store\nLab 4: sharded key/value store")]),e._v(" "),a("p",[e._v("Lab grades depend on how many test cases you pass\nwe give you the tests, so you know whether you'll do well")]),e._v(" "),a("p",[e._v("MAIN TOPICS")]),e._v(" "),a("p",[e._v("This is a course about infrastructure for applications.")]),e._v(" "),a("ul",[a("li",[e._v("Storage.")]),e._v(" "),a("li",[e._v("Communication. (6.829 计算机网络相关)")]),e._v(" "),a("li",[e._v("Computation.")])]),e._v(" "),a("p",[e._v("The big goal: abstractions that hide the complexity of distribution.\nA couple of topics will come up repeatedly in our search.")]),e._v(" "),a("p",[e._v("Topic: fault tolerance\n分布式系统一定会在某处有错误, 所以必须做好错误处理措施\n1000s of servers, big network -> always something broken\nWe'd like to hide these failures from the application.\nWe often want:\nAvailability -- app can make progress despite failures\nRecoverability -- app will come back to life when failures are repaired")]),e._v(" "),a("p",[e._v("Non-Volatile Storage(NVS): 非易失性存储 (NVS) 库主要用于在 flash 中存储键值格式的数据。NVS 最适合存储一些较小的数据，而非字符串或二进制大对象 (BLOB) 等较大的数据。")]),e._v(" "),a("p",[e._v("Big idea: replicated servers. 备份系统\nIf one server crashes, can proceed using the other(s).\nVery hard to get right\nserver may not have crashed, but just unreachable for some\nbut still serving requests from clients")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v("Labs 1, 2 and 3\n")])])]),a("p",[e._v('Topic: consistency\nGeneral-purpose infrastructure needs well-defined behavior.\nE.g. "Get(k) yields the value from the most recent Put(k,v)."\nAchieving good behavior is hard!\n"Replica" servers are hard to keep identical.')]),e._v(" "),a("p",[e._v("Topic: performance\nThe goal: scalable throughput  可伸缩性/可扩展性\nNx servers -> Nx total throughput via parallel CPU, disk, net.\nScaling gets harder as N grows:\nLoad im-balance, stragglers, slowest-of-N latency.\nNon-parallelizable code: initialization, interaction.\nBottlenecks from shared resources, e.g. network.\nSome performance problems aren't easily solved by scaling 扩展不能解决一切性能问题, 例如拓展多台web服务器会将瓶颈转移至数据库\ne.g. quick response time for a single user request\ne.g. all users want to update the same data\noften requires better design rather than just more computers\nLab 4")]),e._v(" "),a("p",[e._v("Topic: Fault-tolerance, consistency, and performance are enemies.\nStrong fault tolerance requires communication\ne.g., send data to backup\nStrong consistency requires communication, 强一致性\ne.g. Get() must check for a recent Put().\nMany designs provide only weak consistency, to gain speed. 弱一致性\ne.g. Get() does "),a("em",[e._v("not")]),e._v(" yield the latest Put()!\nPainful for application programmers but may be a good trade-off.\nMany design points are possible in the consistency/performance spectrum!")]),e._v(" "),a("blockquote",[a("p",[e._v("强一致性（Strict Consistency）也称为：原子一致性（Atomic Consistency）/ 线性一致性（Linearizable Consistency）, 任何一次读都能读到某个数据的最近一次写的数据。系统中的所有进程，看到的操作顺序，都和全局时钟下的顺序一致。")])]),e._v(" "),a("blockquote",[a("p",[e._v("弱一致性: 数据更新后，如果能容忍后续的访问只能访问到部分或者全部访问不到，则是弱一致性。")])]),e._v(" "),a("p",[e._v("Topic: implementation\nRPC, threads, concurrency control.\nThe labs...")]),e._v(" "),a("p",[e._v("RPC: (Remote Procedure Call) 远程过程调用。一个通俗的描述是：客户端在不知道调用细节的情况下，调用存在于远程计算机上的某个对象，就像调用本地应用程序中的对象一样。")]),e._v(" "),a("p",[e._v("HISTORICAL CONTEXT\nLocal-area networks and Internet apps (since 1980s)\n10-100s machines: AFS\nInternet-scale apps: DNS and Email\nData centers (late 1990s/early 2000s)\nWeb sites with many users (many millions) and much data\nGoogle, Yahoo, Facebook, Amazon, Microsoft, etc.\nEarly apps: web search, email, shopping, etc.\nExplosion of cool and interesting systems\n> 1000s of machines\nSystems mostly for internal use, engineers wrote research papers about them\nCloud computing\nUsers outsourcing computation/storage to cloud providers\nUsers run their own big web sites on clouds\nUsers run large computations of lots of data (e.g., machine learning)\n=> Much new user-facing distributed systems infrastructure\nCurrent state: very active area of research and development in academia and industry\nHard to keep up with!\nSome systems in the 6.824 papers are dated, but concepts are still relevant\n6.824: heavy on fault-tolerance/storage\nbut touches on communication and computation too")]),e._v(" "),a("h2",{attrs:{id:"case-study-mapreduce"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#case-study-mapreduce"}},[e._v("#")]),e._v(" CASE STUDY: MapReduce")]),e._v(" "),a("p",[e._v("MapReduce最早是由Google公司研究提出的一种面向大规模数据处理的并行计算模型和方法(搜索引擎业务需要)。MapReduce的灵感来源于函数式语言（比如Lisp）中的内置函数map和reduce。")]),e._v(" "),a("p",[e._v("它是一个并行计算与运行软件框架（Software Framework）。它提供了一个庞大但设计精良的并行计算软件框架，能自动完成计算任务的并行化处理，自动划分计算数据和计算任务，在集群节点上自动分配和执行任务以及收集计算结果，将数据分布存储、数据通信、容错处理等并行计算涉及到的很多系统底层的复杂细节交由系统负责处理，大大减少了软件开发人员的负担。")]),e._v(" "),a("p",[e._v("ps: 函数式编程")]),e._v(" "),a("p",[e._v("Let's talk about MapReduce (MR) as a case study\na good illustration of 6.824's main topics\nhugely influential\nthe focus of Lab 1")]),e._v(" "),a("p",[e._v("MapReduce overview\ncontext: multi-hour computations on multi-terabyte data-sets\ne.g. build search index, or sort, or analyze structure of web\nonly practical with 1000s of computers\napplications not written by distributed systems experts\noverall goal: easy for non-specialist programmers\nprogrammer just defines Map and Reduce functions\noften fairly simple sequential code\nMR takes care of, and hides, all aspects of distribution!")]),e._v(" "),a("p",[e._v('Abstract view of a MapReduce job\ninput is (already) split into M files\nInput1 -> Map -> a,1 b,1\nInput2 -> Map ->     b,1\nInput3 -> Map -> a,1     c,1\n|   |   |\n|   |   -> Reduce -> c,1\n|   -----\x3e Reduce -> b,2\n---------\x3e Reduce -> a,2\nMR calls Map() for each input file, produces set of k2,v2\n"intermediate" data\neach Map() call is a "task"\nMR gathers all intermediate v2\'s for a given k2,\nand passes each key + values to a Reduce call\nfinal output is set of <k2,v3> pairs from Reduce()s')]),e._v(" "),a("p",[e._v('Example: word count\ninput is thousands of text files\nMap(k, v)\nsplit v into words\nfor each word w\nemit(w, "1")\nReduce(k, v)\nemit(len(v))')]),e._v(" "),a("p",[e._v('MapReduce scales well:\nN "worker" computers get you Nx throughput.\nMaps()s can run in parallel, since they don\'t interact.\nSame for Reduce()s.\nSo you can get more throughput by buying more computers.')]),e._v(" "),a("p",[e._v("MapReduce hides many details:\nsending app code to servers\ntracking which tasks are done\nmoving data from Maps to Reduces\nbalancing load over servers\nrecovering from failures")]),e._v(" "),a("p",[e._v("However, MapReduce limits what apps can do:\nNo interaction or state (other than via intermediate output).\nNo iteration, no multi-stage pipelines.\nNo real-time or streaming processing.")]),e._v(" "),a("p",[e._v("Input and output are stored on the GFS cluster file system\nMR needs huge parallel input and output throughput.\nGFS splits files over many servers, in 64 MB chunks\nMaps read in parallel\nReduces write in parallel\nGFS also replicates each file on 2 or 3 servers\nHaving GFS is a big win for MapReduce")]),e._v(" "),a("p",[e._v("GFS(谷歌文件系统)是一个可扩展的分布式文件系统，用于大型的、分布式的、对大量数据进行访问的应用。它运行于廉价的普通硬件上，并提供容错功能。它可以给大量的用户提供总体性能较高的服务。")]),e._v(" "),a("p",[e._v("What will likely limit the performance?\nWe care since that's the thing to optimize.\nCPU? memory? disk? network?\nIn 2004 authors were limited by network capacity.\nWhat does MR send over the network?\nMaps read input from GFS.\nReduces read Map output.\nCan be as large as input, e.g. for sorting.\nReduces write output files to GFS.\n[diagram: servers, tree of network switches]\nIn MR's all-to-all shuffle, half of traffic goes through root switch.\nPaper's root switch: 100 to 200 gigabits/second, total\n1800 machines, so 55 megabits/second/machine.\n55 is small, e.g. much less than disk or RAM speed.\nToday: networks and root switches are much faster relative to CPU/disk.")]),e._v(" "),a("p",[e._v("Some details (paper's Figure 1):\none coordinator, that hands out tasks to workers and remembers progress.")]),e._v(" "),a("ol",[a("li",[e._v("coordinator gives Map tasks to workers until all Maps complete\nMaps write output (intermediate data) to local disk\nMaps split output, by hash, into one file per Reduce task")]),e._v(" "),a("li",[e._v("after all Maps have finished, coordinator hands out Reduce tasks\neach Reduce fetches its intermediate output from (all) Map workers\neach Reduce task writes a separate output file on GFS")])]),e._v(" "),a("p",[e._v("How does MR minimize network use?\nCoordinator tries to run each Map task on GFS server that stores its input.\nAll computers run both GFS and MR workers\nSo input is read from local disk (via GFS), not over network.\nIntermediate data goes over network just once.\nMap worker writes to local disk.\nReduce workers read directly from Map workers, not via GFS.\nIntermediate data partitioned into files holding many keys.\nR is much smaller than the number of keys.\nBig network transfers are more efficient.")]),e._v(" "),a("p",[e._v("How does MR get good load balance?\nWasteful and slow if N-1 servers have to wait for 1 slow server to finish.\nBut some tasks likely take longer than others.\nSolution: many more tasks than workers.\nCoordinator hands out new tasks to workers who finish previous tasks.\nSo no task is so big it dominates completion time (hopefully).\nSo faster servers do more tasks than slower ones, finish abt the same time.")]),e._v(" "),a("p",[e._v("What about fault tolerance?\nI.e. what if a worker crashes during a MR job?\nWe want to completely hide failures from the application programmer!\nDoes MR have to re-run the whole job from the beginning?\nWhy not?\nMR re-runs just the failed Map()s and Reduce()s.\nSuppose MR runs a Map twice, one Reduce sees first run's output,\nanother Reduce sees the second run's output?\nCorrectness requires re-execution to yield exactly the same output.\nSo Map and Reduce must be pure deterministic functions:\nthey are only allowed to look at their arguments.\nno state, no file I/O, no interaction, no external communication.\nWhat if you wanted to allow non-functional Map or Reduce?\nWorker failure would require whole job to be re-executed,\nor you'd need to create synchronized global checkpoints.")]),e._v(" "),a("p",[e._v("Details of worker crash recovery:")]),e._v(" "),a("ul",[a("li",[e._v("Map worker crashes:\ncoordinator notices worker no longer responds to pings\ncoordinator knows which Map tasks it ran on that worker\nthose tasks' intermediate output is now lost, must be re-created\ncoordinator tells other workers to run those tasks\ncan omit re-running if Reduces already fetched the intermediate data")]),e._v(" "),a("li",[e._v("Reduce worker crashes.\nfinished tasks are OK -- stored in GFS, with replicas.\ncoordinator re-starts worker's unfinished tasks on other workers.")])]),e._v(" "),a("p",[e._v("Other failures/problems:")]),e._v(" "),a("ul",[a("li",[e._v("What if the coordinator gives two workers the same Map() task?\nperhaps the coordinator incorrectly thinks one worker died.\nit will tell Reduce workers about only one of them.")]),e._v(" "),a("li",[e._v("What if the coordinator gives two workers the same Reduce() task?\nthey will both try to write the same output file on GFS!\natomic GFS rename prevents mixing; one complete file will be visible.")]),e._v(" "),a("li",[e._v('What if a single worker is very slow -- a "straggler"?\nperhaps due to flakey hardware.\ncoordinator starts a second copy of last few tasks.')]),e._v(" "),a("li",[e._v('What if a worker computes incorrect output, due to broken h/w or s/w?\ntoo bad! MR assumes "fail-stop" CPUs and software.')]),e._v(" "),a("li",[e._v("What if the coordinator crashes?")])]),e._v(" "),a("p",[e._v("Current status?\nHugely influential (Hadoop, Spark, &c).\nProbably no longer in use at Google.\nReplaced by Flume / FlumeJava (see paper by Chambers et al).\nGFS replaced by Colossus (no good description), and BigTable.")]),e._v(" "),a("p",[e._v("Conclusion\nMapReduce single-handedly made big cluster computation popular.")]),e._v(" "),a("ul",[a("li",[e._v("Not the most efficient or flexible.")])]),e._v(" "),a("ul",[a("li",[e._v("Scales well.")]),e._v(" "),a("li",[e._v("Easy to program -- failures and data movement are hidden.\nThese were good trade-offs in practice.\nWe'll see some more advanced successors later in the course.\nHave fun with the lab!")])])])}),[],!1,null,null,null);t.default=o.exports}}]);